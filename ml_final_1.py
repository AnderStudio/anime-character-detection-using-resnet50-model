# -*- coding: utf-8 -*-
"""ML_Final-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pi4qNaXnK_zL6xg8wiHTvdjigC1ixpzm
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os
import random

import numpy as np
import pandas as pd
from PIL import Image

import matplotlib.pyplot as plt
import tensorflow as tf
import sklearn

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import utils
from tensorflow.keras.models import Sequential
from sklearn import metrics

# imgs from dataset
X_train = []
Y_train = []
for i in range(2754):
  img = Image.open("/content/drive/MyDrive/ml_img/resize_total/resize_train_{i}.jpg".format(i=i))
  X_train.append(np.asarray(img))

X_train

# 這個先不要run
Y_train = {'Atack of Titan': [], 'Jujutsu Kaisen': [], 'Kimetsu no Yaiba': [], 'Sword Art Online': []}
for i in range(2754):
  if i < 635:
    Y_train['Atack of Titan'].append(int(1))
    Y_train['Jujutsu Kaisen'].append(int(0))
    Y_train['Kimetsu no Yaiba'].append(int(0))
    Y_train['Sword Art Online'].append(int(0))
  elif i >= 635 and i < 1187:
    Y_train['Atack of Titan'].append(int(0))
    Y_train['Jujutsu Kaisen'].append(int(1))
    Y_train['Kimetsu no Yaiba'].append(int(0))
    Y_train['Sword Art Online'].append(int(0))
  elif i >= 1187 and i < 2092:
    Y_train['Atack of Titan'].append(int(0))
    Y_train['Jujutsu Kaisen'].append(int(0))
    Y_train['Kimetsu no Yaiba'].append(int(1))
    Y_train['Sword Art Online'].append(int(0))
  else:
    Y_train['Atack of Titan'].append(int(0))
    Y_train['Jujutsu Kaisen'].append(int(0))
    Y_train['Kimetsu no Yaiba'].append(int(0))
    Y_train['Sword Art Online'].append(int(1))

Y_train = []
for i in range(2754):
  if i < 635:
    Y_train.append(int(0))
  elif i >= 635 and i < 1187:
    Y_train.append(int(1))
  elif i >= 1187 and i < 2092:
    Y_train.append(int(2))
  else:
    Y_train.append(int(3))

shuffle_train = []
for i in range(2754):
  shuffle_train.append((X_train[i], Y_train[i]))
random.shuffle(shuffle_train)
#shuffle_train

X_train = []
Y_train = []
for i in range(2574):
  X_train.append(shuffle_train[i][0])
  Y_train.append(shuffle_train[i][1])

X_train = np.array(X_train)
Y_train = np.array(Y_train)
#Y_train = pd.DataFrame(Y_train)

len(X_train)
#len(Y_train)
print(X_train.shape)

# test imgs from dataset
X_test = []
#Y_train = []
for i in range(171):
  img = Image.open("/content/drive/MyDrive/ml_img/test/test_{i}.jpg".format(i=i))
  #img.save("test_c.jpg",quality=65)
  X_test.append(np.asarray(img.resize( (288, 160), Image.BILINEAR )))
  #X_test.append(np.asarray(Image.open("/content/drive/MyDrive/test/test_{i}.jpg".format(i=i))))

X_test = np.array(X_test)

# 1280 * 720 img size
img_height = 160
img_width = 288

# class number
num_classes = 4

from tensorflow.keras.applications import ResNet50

try_model = tf.keras.applications.resnet_v2.ResNet50V2(
    include_top=False, weights='imagenet', input_tensor=None,
    input_shape=(img_height, img_width, 3), 
    classes = 4, pooling='max', classifier_activation = 'softmax'
)

# Compile the model
try_model.compile(optimizer='SGD',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

try_model.summary()

epochs=15
try_history = try_model.fit(
  X_train, Y_train, batch_size = 32,
  validation_split = 0.2,
  epochs = epochs
)

# predict
img_array = X_test
#img_array = tf.expand_dims(img_array, 0) # Create a batch
print(X_test)
predictions = try_model.predict(X_test)

try_model.save('saved_trymodel.h5')

print(predictions.shape)

# Create the model

data_augmentation = keras.Sequential(
  [
    #layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1, input_shape = (img_height, img_width, 3)),
    layers.RandomZoom(0.3),
  ]
)

#num_classes = len(class_names)

model = Sequential([
  data_augmentation,
  layers.Rescaling(1./255),
  layers.Conv2D(32, 8, strides = 2, padding = 'same', activation = 'relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(128, 8, strides = 2, padding = 'same', activation = 'relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(128, 16, strides = 2, padding = 'same', activation = 'relu'),
  layers.MaxPooling2D(),
  layers.Dropout(0.3),
  layers.Flatten(),
  layers.Dense(128, activation = 'softmax'),
  layers.Dense(num_classes)
])

# Compile the model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.summary()

epochs=10
history = model.fit(
  X_train, Y_train, batch_size = 64,
  validation_split = 0.2,
  epochs = epochs
)

# Save the entire model as a SavedModel.
!mkdir -p saved_model
model.save("test_model", save_format = 'h5')

# visualization of the training result
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

# predict
img_array = X_test
#img_array = tf.expand_dims(img_array, 0) # Create a batch

predictions = model.predict(X_test)

predictions

Y_pred = {}
Y_pred['Jujutsu'] = np.argmax(predictions, axis = 1)
Y_pred = pd.DataFrame(Y_pred)

error = 0
for i in Y_pred['Jujutsu']:
  if i == 0:
    error += 1
print(1-float(error/171))

#output_path = '108070038_basic_prediction.csv'
#Y_pred.to_csv(output_path)

! pip install git+https://github.com/divamgupta/image-segmentation-keras

import keras_segmentation.models as sm

#sm.set_framework('tf.keras')

#sm.framework()

from keras_segmentation.models.unet import vgg_unet

model = vgg_unet(n_classes=50 ,  input_height=480, input_width=864  )

new_model = tf.keras.models.load_model('test_model')

new_model.summary()